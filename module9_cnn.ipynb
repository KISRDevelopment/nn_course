{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3994d086-2d85-4040-933c-04ecd6e88814",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "* So far we've built fully connected feed-forward (FF) NNs, where each input node is connected to each hidden node.\n",
    "* A fully connected NN that has a 30 unit hidden layer and accepts 28x28 images has $28 \\times 28 \\times 30 + 30 = 23,550$ weights between the input and hidden layer\n",
    "* The number of weights will quickly grow if we start dealing with larger color images which have more pixels and where each pixel has three numbers associated with it (red, blue, and green)\n",
    "* The network will quickly overfit as a result\n",
    "* For images, the standard way to handle this problem is via the convolutional neural network which consists of convolutional layers, pooling layers, and the usual fully-connected layers.\n",
    "* Those networks have drastically fewer parameters than FF NNs.\n",
    "\n",
    "## Convolution Layer\n",
    "\n",
    "The convolution layer makes two assumptions about its inputs:\n",
    "\n",
    "1. Inputs that are nearby are related.\n",
    "2. A detector that could detect a pattern in (x, y) can be used to detect the same pattern in other locations in the image\n",
    "\n",
    "Both assumptions are very reasonable in images: pixels that are nearby are likely to share statistical properties and a detector that can detect edges at the top of the image, can also detect edges at the bottom.\n",
    "\n",
    "### One Dimensional Convolution\n",
    "Let's see how basic convolution operator works in the 1D input case (recall that images are 2D). A single neuron in a convolution layer defines a receptive field that operates over a limited range of inputs. The neuron slides this receptive field over the input to produce the final outputs:\n",
    "\n",
    "![alt text](figures/1dconv.jpg)\n",
    "\n",
    "In the Figure, the neuron (opaque magenta) defines a simple operation over the sequence: it computes the average of pairs of neighbors. At the first step, the neuron computes the average of the first two elements. At the second step the neuron computes the average of the second and third elements, and so on. \n",
    "\n",
    "The neuron has two weights: 0.5 and 0.5 which mean that both inputs are weighted equally, so it computes a straightforward average. But we can change the weights to anything, and, as you might have guessed, those weights will be free parameters of a convolutional neural network. \n",
    "\n",
    "It is important to note that the *same weights* are applied across the entire input.\n",
    "\n",
    "Here's an example of how one might implement 1D convolution in numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c90cd92-5e1a-4874-b03f-13ce89c2bcff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5,  3. ,  4.5,  6. ,  7.5,  9. , 10.5, 12. ,  8.5])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here's a 1D \"image\"\n",
    "input_data = np.array([1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "# a convolutional layer neuron defines\n",
    "convolution_kernel = np.array([0.5, 0.5, 0.5])\n",
    "\n",
    "y_same = np.convolve(input_data, convolution_kernel, \"same\")\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1da62e-e5e2-4fe1-bcab-418dcbe62533",
   "metadata": {},
   "source": [
    "The `\"same\"` argument tells numpy to add $m-1$ zeros at the left of the sequence (where $m$ is the size of the convolution kernel, 3 in this case) so that the output of the convolution operation has the same size as the input. There are other padding options:\n",
    "\n",
    "* `\"full\"`: adds $m-1$ zeros at both ends of the sequence. The final output has size $n + m - 1$.\n",
    "* `\"valid\"`: computes entries where the kernel and the input sequence fully overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "326884ee-7e2a-4bdc-9a47-6e8be2ee31c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 14 34 34  8]\n",
      "[14 34 34]\n"
     ]
    }
   ],
   "source": [
    "x = [6, 2]\n",
    "h = [1, 2, 5, 4]\n",
    "\n",
    "y = np.convolve(h, x, \"full\")\n",
    "print(y)\n",
    "\n",
    "y = np.convolve(h, x, \"valid\")\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4815c7b-a36b-43fb-9499-8ffaf2089331",
   "metadata": {},
   "source": [
    "We call the convolution operation with a specific kernel (weights) a filter.\n",
    "\n",
    "### Two Dimensional Convolution\n",
    "\n",
    "https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks\n",
    "\n",
    "# Example (Simple MNIST convnet from Keras Documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29e37c65-7089-4568-9dc3-1bb26b2ebd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9540b71-9143-439e-a87e-a67c12c425b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ddc91f6-76e5-4206-9db2-1f595f6b62f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 07:15:37.654692: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-13 07:15:37.654845: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b62da97b-046b-46bf-858e-9cbcc7a0939f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 07:16:36.119634: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-13 07:16:36.119809: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-12-13 07:16:36.235074: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "422/422 [==============================] - ETA: 0s - loss: 0.3723 - accuracy: 0.8854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 07:16:43.750152: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 8s 15ms/step - loss: 0.3723 - accuracy: 0.8854 - val_loss: 0.0856 - val_accuracy: 0.9775\n",
      "Epoch 2/15\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.1168 - accuracy: 0.9639 - val_loss: 0.0624 - val_accuracy: 0.9828\n",
      "Epoch 3/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0879 - accuracy: 0.9728 - val_loss: 0.0477 - val_accuracy: 0.9873\n",
      "Epoch 4/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0735 - accuracy: 0.9776 - val_loss: 0.0455 - val_accuracy: 0.9880\n",
      "Epoch 5/15\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0642 - accuracy: 0.9800 - val_loss: 0.0415 - val_accuracy: 0.9892\n",
      "Epoch 6/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0601 - accuracy: 0.9815 - val_loss: 0.0368 - val_accuracy: 0.9898\n",
      "Epoch 7/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0538 - accuracy: 0.9830 - val_loss: 0.0386 - val_accuracy: 0.9890\n",
      "Epoch 8/15\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0486 - accuracy: 0.9847 - val_loss: 0.0352 - val_accuracy: 0.9917\n",
      "Epoch 9/15\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0468 - accuracy: 0.9859 - val_loss: 0.0318 - val_accuracy: 0.9912\n",
      "Epoch 10/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0441 - accuracy: 0.9860 - val_loss: 0.0314 - val_accuracy: 0.9912\n",
      "Epoch 11/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0414 - accuracy: 0.9867 - val_loss: 0.0319 - val_accuracy: 0.9912\n",
      "Epoch 12/15\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0401 - accuracy: 0.9869 - val_loss: 0.0290 - val_accuracy: 0.9918\n",
      "Epoch 13/15\n",
      "422/422 [==============================] - 7s 16ms/step - loss: 0.0378 - accuracy: 0.9876 - val_loss: 0.0315 - val_accuracy: 0.9925\n",
      "Epoch 14/15\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0344 - accuracy: 0.9886 - val_loss: 0.0304 - val_accuracy: 0.9920\n",
      "Epoch 15/15\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0342 - accuracy: 0.9893 - val_loss: 0.0314 - val_accuracy: 0.9918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a3207e20>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9f74818-2fb9-42ca-ba61-df45aa4c2921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.025478513911366463\n",
      "Test accuracy: 0.9922000765800476\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94781cd8-3e58-4fb0-98ed-239163cfc98e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
